{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ли отобрать наиболее значимые признаки с помощью PCA?\n",
    "\n",
    "---- Нет, он предназначен для снижения размерности, а не для отбора уже имеющихся.\n",
    "\n",
    "2*. Примите участие в одном или двух соревнованиях и пришлите\n",
    "\n",
    "свой псевдоним на Kaggle и ссылку на github с решением соревнования\n",
    "\n",
    "по регрессии ()\n",
    "\n",
    "------ JaneCalm\n",
    "\n",
    "или классификации (https://www.kaggle.com/c/choose-tutors).\n",
    "\n",
    "В скрипте можно использовать только эти импорты:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "TRAIN_DATASET_PATH = 'train.csv'\n",
    "TEST_DATASET_PATH = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>lesson_price</th>\n",
       "      <th>qualification</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "      <th>biology</th>\n",
       "      <th>english</th>\n",
       "      <th>geography</th>\n",
       "      <th>history</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   age  years_of_experience  lesson_price  qualification  physics  \\\n",
       "0   0  40.0                  0.0        1400.0            1.0      1.0   \n",
       "1   1  48.0                  4.0        2850.0            3.0      1.0   \n",
       "2   2  39.0                  0.0        1200.0            1.0      0.0   \n",
       "3   3  46.0                  5.0        1400.0            1.0      0.0   \n",
       "4   4  43.0                  1.0        1500.0            1.0      0.0   \n",
       "\n",
       "   chemistry  biology  english  geography  history  mean_exam_points  \n",
       "0        0.0      0.0      0.0        1.0      0.0              63.0  \n",
       "1        0.0      0.0      0.0        0.0      0.0              86.0  \n",
       "2        0.0      0.0      0.0        0.0      0.0              53.0  \n",
       "3        0.0      0.0      0.0        0.0      0.0              56.0  \n",
       "4        0.0      0.0      0.0        0.0      0.0              59.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 12)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAME = 'mean_exam_points'\n",
    "FEATURE_NAMES = ['age', 'years_of_experience', 'lesson_price', 'qualification',\n",
    "       'physics', 'chemistry', 'biology', 'english', 'geography', 'history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURE_NAMES].values\n",
    "Y = df[TARGET_NAME].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Возьмем 10 признаков и 10000 объектов\n",
    "n_features = 10\n",
    "n_objects = 10000\n",
    "\n",
    "# сгенерируем вектор истинных весов\n",
    "#w_true = np.random.normal(size=(n_features, ))\n",
    "\n",
    "# сгенерируем матрицу X, вычислим Y с добавлением случайного шума\n",
    "#X = np.random.uniform(-7, 7, (n_objects, n_features))\n",
    "#Y = X.dot(w_true) + np.random.normal(0, 0.5, size=(n_objects))\n",
    "\n",
    "# возьмем нулевые начальные веса\n",
    "w = np.zeros(n_features)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализуем функцию, определяющую среднеквадратичную ошибку\n",
    "def mserror(X, w, y_pred):\n",
    "    y = X.dot(w)\n",
    "    return (sum((y - y_pred)**2)) / len(y)\n",
    "def calc_mse(y, y_pred):\n",
    "  err = np.mean((y - y_pred)**2)\n",
    "  return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В случае использования нормального уравнения функционал ошибки составляет 88.8027\n"
     ]
    }
   ],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.linalg.solve((X.T).dot(X), (X.T).dot(y))\n",
    "\n",
    "normal_eq_w = normal_equation(X, Y)\n",
    "print(f'В случае использования нормального уравнения функционал ошибки составляет {round(mserror(X, normal_eq_w, Y), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50924797, 0.19438164, 0.01427329, 7.35715911, 6.36555615,\n",
       "       1.26278512, 2.1159237 , 2.31825251, 1.06574434, 0.54044291])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_eq_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[FEATURE_NAMES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_predict = X_test.dot(normal_eq_w)\n",
    "#submissions = pd.concat([test['Id'], pd.Series(Y_predict)], axis=1)\n",
    "#submissions = submissions.rename(columns={0: 'mean_exam_points'})\n",
    "#submissions.to_csv('Kalmina_1.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['inter']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE_NAMES = ['inter', 'age', 'years_of_experience', 'lesson_price', 'qualification',\n",
    "#       'physics', 'chemistry', 'biology', 'english', 'geography', 'history']\n",
    "#X = df[FEATURE_NAMES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=X.T\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.85714286e-02, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 7.14285714e-04, 0.00000000e+00],\n",
       "       [1.68421053e-02, 1.40350877e-03, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.25000000e-02, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [2.72000000e-02, 8.00000000e-04, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.00000000e-02, 2.72727273e-03, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.41379310e-02, 0.00000000e+00, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm = X.copy()\n",
    "X_norm = X_norm.astype(np.float64)\n",
    "for p in range(len(X_norm)):\n",
    "    X_norm[p] = (X[p] - X[p].min()) / (X[p].max() - X[p].min())\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res\n",
    "\n",
    "X_st = X.copy().astype(np.float64)\n",
    "for s in range(len(X_st)):\n",
    "    X_st[s] = calc_std_feat(X[s])\n",
    "#X_st = X_st.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, alpha=3e-2):\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    err_min = 10000\n",
    "    W_min = []\n",
    "    for i in range(1, iterations+1):\n",
    "        y_pred = np.dot(W, X)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        W -= (alpha * (1/n * 2 * np.dot((y_pred - y), X.T)))\n",
    "        if err < err_min:\n",
    "            err_min = err\n",
    "            W_min.append(W)\n",
    "        if i % (iterations / 100) == 0:\n",
    "            print(i, W, err)\n",
    "    return W_min, err_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w = np.zeros(11)\n",
    "w_list = [w.copy()]\n",
    "errors = []\n",
    "# шаг градиентного спуска\n",
    "eta = 0.000003\n",
    "max_iter = 1e6\n",
    "# критерий сходимости (разница весов, при которой алгоритм останавливается)\n",
    "min_weight_dist = 1e-10\n",
    "# зададим начальную разницу весов большим числом\n",
    "weight_dist = np.inf\n",
    "iter_num = 0\n",
    "# ход градиентного спуска\n",
    "new_w = np.random.randn(X.shape[0])\n",
    "n = X_st.shape[1]\n",
    "while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "    # генерируем случайный индекс объекта выборки\n",
    "    train_ind = np.random.randint(X_st.shape[0])\n",
    "    y_pred = np.dot(w, X_st)\n",
    "    new_w -= (eta * (1/n * 2 * np.dot((y_pred - Y), X_st.T)))\n",
    "    weight_dist = np.linalg.norm(new_w - w, ord=2) \n",
    "    w_list.append(new_w.copy())\n",
    "    errors.append(mserror(X_st.T, new_w, Y))   \n",
    "    iter_num += 1\n",
    "    w = new_w\n",
    "    print({mserror(X_st.T, new_w, Y)})\n",
    "    \n",
    "    \n",
    "w_list = np.array(w_list)\n",
    "\n",
    "print(f'В случае использования стохастического градиентного спуска функционал ошибки составляет {round(errors[-1], 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w_pred, err_pred = eval_model(X_st, Y, iterations=10000, alpha=3e-2)\n",
    "#print(w_pred, err_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['inter']=1\n",
    "#X_test = test[FEATURE_NAMES].values\n",
    "#X_test=X_test.T\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_st = X_test.copy().astype(np.float64)\n",
    "for s in range(len(X_test_st)):\n",
    "    X_test_st[s] = calc_std_feat(X_test[s])\n",
    "#X_test_st = X_test_st.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_st = X_test_st.T\n",
    "#Y_predict_3 = X_test_st.dot(w_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sgd_model(X, y, iterations, qty_in_batch, alpha=1e-4):\n",
    "  W = np.random.randn(X.shape[0])\n",
    "  n = X.shape[1]\n",
    "  n_batch = n // qty_in_batch\n",
    "  if n % qty_in_batch != 0:\n",
    "    n_batch += 1\n",
    "  for i in range(1, iterations+1):\n",
    "    for b in range(n_batch):\n",
    "      start_ = qty_in_batch*b\n",
    "      end_ = qty_in_batch*(b+1)\n",
    "      \n",
    "      # print(b, n_batch, start_, end_)\n",
    "      \n",
    "      X_tmp = X[:, start_ : end_]\n",
    "      y_tmp = y[start_ : end_]\n",
    "      y_pred_tmp = np.dot(W, X_tmp)\n",
    "      err = calc_mse(y_tmp, y_pred_tmp)\n",
    "      W -= (alpha * (1/n * 2 * np.dot((y_pred_tmp - y_tmp), X_tmp.T)))\n",
    "    if i % (iterations / 10) == 0:\n",
    "      print(i, W, err)\n",
    "  return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w_pred_2 = eval_sgd_model(X_st, Y, iterations=2000, qty_in_batch=5, alpha=1e-2)\n",
    "#w_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_reg2(X, y, iterations, alpha=1e-4, lambda_=1e-8):\n",
    "  np.random.seed(42)\n",
    "  W = np.random.randn(X.shape[0])\n",
    "  n = X.shape[1]\n",
    "  for i in range(1, iterations+1):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    W -= alpha * (1/n * 2 * np.dot((y_pred - y), X.T) + lambda_ * W) \n",
    "    if i % (iterations / 10) == 0:\n",
    "      print(i, W, err)\n",
    "  return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg2 = eval_model_reg2(X_st, Y, iterations=500000, alpha=1e-3, lambda_=1e-8)\n",
    "#reg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_predict_4 = X_test_st.dot(reg2)\n",
    "#submissions = pd.concat([test['Id'], pd.Series(Y_predict_4)], axis=1)\n",
    "#submissions = submissions.rename(columns={0: 'mean_exam_points'})\n",
    "#submissions.to_csv('Kalmina_reg2.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_reg1(X, y, iterations, alpha=1e-4, lambda_=1e-8):\n",
    "  np.random.seed(42)\n",
    "  W = np.random.randn(X.shape[0])\n",
    "  n = X.shape[1]\n",
    "  for i in range(1, iterations+1):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    W -= alpha * (1/n * 2 * np.dot((y_pred - y), X.T) + lambda_ * np.sign(W)) \n",
    "    if i % (iterations / 10) == 0:\n",
    "      print(i, W, err)\n",
    "  return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg1 = eval_model_reg1(X_st, Y, iterations=500000, alpha=1e-3, lambda_=1e-8)\n",
    "#reg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И класс терминального узла (листа)\n",
    "\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        #  найдем значение как среднее по выборке   \n",
    "        prediction = np.mean(self.labels)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И класс дерева\n",
    "class Tree:\n",
    "\n",
    "  def __init__(self, max_depth=50):\n",
    "    self.max_depth = max_depth\n",
    "    self.tree = None\n",
    "\n",
    "  # Расчёт дисперсии значений\n",
    "  def dispersion(self, labels):\n",
    "    return np.std(labels)\n",
    "\n",
    "  # Расчет качества\n",
    "\n",
    "  def quality(self, left_labels, right_labels, current_dispersion):\n",
    "\n",
    "    # доля выбоки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    return current_dispersion - p * self.dispersion(left_labels) - (1 - p) * self.dispersion(right_labels)\n",
    "\n",
    "    # Разбиение датасета в узле\n",
    "\n",
    "  def split(self, data, labels, index, t):\n",
    "    \n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "    # Нахождение наилучшего разбиения\n",
    "\n",
    "  def find_best_split(self, data, labels):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_leaf = 5\n",
    "\n",
    "    current_dispersion = self.dispersion(labels)\n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "      # будем проверять только уникальные значения признака, исключая повторения\n",
    "      t_values = np.unique([row[index] for row in data])\n",
    "      \n",
    "      for t in t_values:\n",
    "        true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "        #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "        if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "          continue\n",
    "        \n",
    "        current_quality = self.quality(true_labels, false_labels, current_dispersion)\n",
    "        \n",
    "        #  выбираем порог, на котором получается максимальный прирост качества\n",
    "        if current_quality > best_quality:\n",
    "          best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index\n",
    "\n",
    "    # Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "  def build_tree(self, data, labels, tree_depth, max_depth):\n",
    "\n",
    "    quality, t, index = self.find_best_split(data, labels)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    if quality == 0:\n",
    "      return Leaf(data, labels)\n",
    "\n",
    "    # Базовый случай (2) - прекращаем рекурсию, когда достигнута максимальная глубина дерева\n",
    "    if tree_depth >= max_depth:\n",
    "      return Leaf(data, labels)\n",
    "\n",
    "    # Увеличиваем глубину дерева на 1\n",
    "    tree_depth += 1\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = self.split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = self.build_tree(true_data, true_labels, tree_depth, max_depth)\n",
    "    false_branch = self.build_tree(false_data, false_labels, tree_depth, max_depth)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)\n",
    "\n",
    "  def predict_object(self, obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "      answer = node.prediction\n",
    "      return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "      return self.predict_object(obj, node.true_branch)\n",
    "    else:\n",
    "      return self.predict_object(obj, node.false_branch)\n",
    "\n",
    "  def predict(self, data):\n",
    "    \n",
    "    val = []\n",
    "    for obj in data:\n",
    "      prediction = self.predict_object(obj, self.tree)\n",
    "      val.append(prediction)\n",
    "    return val\n",
    "\n",
    "  def fit(self, data, labels):\n",
    "    self.tree = self.build_tree(data, labels, 0, self.max_depth)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "  \n",
    "  def __init__(self, n_trees, max_depth, coefs, eta):\n",
    "    self.n_trees = n_trees\n",
    "    self.max_depth = max_depth\n",
    "    self.coefs = coefs\n",
    "    self.eta = eta\n",
    "    self.trees = []\n",
    "\n",
    "  def bias(self, y, z):\n",
    "    return (y - z)\n",
    "\n",
    "  def fit(self, X_train, y_train):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    for i in range(self.n_trees):\n",
    "        tree = Tree(max_depth=self.max_depth)\n",
    "\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(self.trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            tree.fit(X_train, y_train)\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            target = self.predict(X_train)\n",
    "            \n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            bias = self.bias(y_train, target)\n",
    "            tree.fit(X_train, bias)\n",
    "\n",
    "        self.trees.append(tree)\n",
    "        \n",
    "    return self\n",
    "\n",
    "  def predict(self, X):\n",
    "    # Реализуемый алгоритм градиентного бустинга будет инициализироваться нулевыми значениями,\n",
    "    # поэтому все деревья из списка trees_list уже являются дополнительными и при предсказании прибавляются с шагом eta\n",
    "    return np.array([sum([self.eta* coef * alg.predict([x])[0] for alg, coef in zip(self.trees, self.coefs)]) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_2(y_pred, y_true):\n",
    "  numerator = ((y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
    "  denominator = ((y_true - np.average(y_true)) ** 2).sum(axis=0,\n",
    "                                                          dtype=np.float64)\n",
    "  return 1 - (numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(X_st, Y, \n",
    "                                                                    test_size = 0.3,\n",
    "                                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число деревьев в ансамбле\n",
    "n_trees = 10\n",
    "\n",
    "# для простоты примем коэффициенты равными 1\n",
    "coefs = [1] * n_trees\n",
    "\n",
    "# Максимальная глубина деревьев\n",
    "max_depth = 6\n",
    "\n",
    "# Шаг\n",
    "eta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoosting(n_trees, max_depth, coefs, eta)\n",
    "gb.fit(train_data, train_labels)\n",
    "train_answers = gb.predict(train_data)\n",
    "test_answers = gb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5889488246130198"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_2(test_answers, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6907182373351788"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_2(train_answers, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GradientBoosting at 0x7fea3595c5d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_final = GradientBoosting(n_trees, max_depth, coefs, eta)\n",
    "gb_final.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = gb_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.94085651, 64.66387139, 48.37453509, ..., 54.73601345,\n",
       "       65.44632684, 69.74647241])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.concat([test['Id'], pd.Series(test_pred)], axis=1)\n",
    "submissions = submissions.rename(columns={0: 'mean_exam_points'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.to_csv('Kalmina_tree_st_last.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
